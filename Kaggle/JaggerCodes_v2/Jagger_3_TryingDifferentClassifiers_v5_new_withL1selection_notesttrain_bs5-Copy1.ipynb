{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZ4n_EpC1WdI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZfaxAof1Wes",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import _pickle\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jMfpG4Bm1Wes"
   },
   "source": [
    "# Data loading and preprocessing\n",
    "Remember to change the path if needed be\n",
    "\n",
    "### Hyperparameters of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YtkqLssT1Wes",
    "outputId": "e43ecc74-6c45-45a2-cf00-ef62c27132a4"
   },
   "outputs": [],
   "source": [
    "m = 2000; M = 12000; \n",
    "bin_size = 5;\n",
    "\n",
    "path = \"D:/GitHub/Machine-Learning/Kaggle/\"\n",
    "# path = \"C:/Users/Javi/Documents/GitHub/Machine-Learning/Kaggle/\"\n",
    "\n",
    "# # Take the data from Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive',force_remount=True)\n",
    "# path = \"/content/drive/My Drive/Colab Notebooks/Kaggle/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = path + 'Kaggle classifiers/bin size 5/'\n",
    "path_results = path + 'Kaggle_results/'\n",
    "\n",
    "ncpu = os.cpu_count()\n",
    "if (ncpu>2): njobs = ncpu - 2; \n",
    "else: njobs = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FvVSX2j1Wes",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "df_train = _pickle.loads(zf.open('TrainData.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read())\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugonC8a31Wes",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spectrum_in_bins(df,m,M,bin_size):\n",
    "    # Now, let's define the mz ranges, and the label associated to each of them (the mean of the limiting values of each bin)\n",
    "    range_min = []; range_max = []; range_label = [];\n",
    "    for mz in range(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_label.append(np.mean([range_min[-1],range_max[-1]]).astype(int))\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    for idx in range(N): \n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        idx_data_in_bins = np.zeros((1,L))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                idx_data_in_bins[0,i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum\n",
    "                idx_data_in_bins[0,i] = 0   \n",
    "\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins[0,:] = idx_data_in_bins[0,:] / np.max(idx_data_in_bins[0,:])\n",
    "        all_data[idx,:] = idx_data_in_bins\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_label, index = df.index)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rd_5RaoI1Wes",
    "outputId": "c15d3f8a-445c-4196-91f2-4d15dd2dd3d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrum regularized!\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop_duplicates(subset='ID_sample') # eliminate duplicates\n",
    "# Let's work without duplicates from now on, to avoid having same sample in training and test_training sets\n",
    "\n",
    "# Extract data (spectra) and targets of the df_train set\n",
    "data_train = df_train.iloc[:,-2:]\n",
    "targets_train = df_train.iloc[:,1:-2]\n",
    "\n",
    "# apply the bins to all spectra, so that our feature space becomes the same for all samples (make them regular, all the same)\n",
    "spectrum_train = spectrum_in_bins(data_train,m,M,bin_size)\n",
    "print('Spectrum regularized!')\n",
    "# these spectrum_... are our X for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw0dOqoZ1Wes"
   },
   "outputs": [],
   "source": [
    "def clean_nan_samples(spectrum,targets, c, cat):\n",
    "# if there are any NaN values, we should remove those samples\n",
    "    if (targets[cat].isnull().sum() > 0).all(): \n",
    "        merged = pd.concat([spectrum , targets],axis=1,copy=True)\n",
    "        clean = merged.dropna(subset=[cat])\n",
    "        Y = clean.iloc[:,-9+c].to_numpy().reshape(-1,)\n",
    "        X = clean.iloc[:,:-9]\n",
    "\n",
    "    else:\n",
    "        Y = targets.iloc[:,c].to_numpy().reshape(-1,)\n",
    "        X = spectrum.copy(deep=True)\n",
    "    return X , Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWkmknnq1WgQ"
   },
   "source": [
    "# Try different classifiers\n",
    "The try_clf function has been built for, given a classifier and a parameter dictionary (for hyperparameter cross-validation), create a classifier for each antibiotic, and return the results. This enables for fast testing of different classifiers. Moreover, the function also takes charge of suppressing NaN values in the targets ocurring for amikacina, levofloxacino and tobramicina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KK7J7QA1WgQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def try_clf(clf,params,n_cv=5,L1_FEATURE_SELECTION=False, feature_vector_list=None):  # new version! (after Sevilla)\n",
    "    # new version --> Incorporates feature selection\n",
    "    t1 = time.time()\n",
    "    \n",
    "    best_classifiers = [];\n",
    "    grid_list = [];\n",
    "    AUC_train = []; AUC_valid = [];\n",
    "    \n",
    "    categories = targets_train.columns[:]    \n",
    "    for c,cat in enumerate(categories):\n",
    "\n",
    "        print([cat]) # indicate in which antibiotic we are\n",
    "        \n",
    "        # Selection of train and test data (depending on whether there are NaN target values)\n",
    "        X_train, Y_train = clean_nan_samples(spectrum_train,targets_train, c, cat)\n",
    "        \n",
    "        if L1_FEATURE_SELECTION: # a boolean that decides whether to apply L1 feature selection (L1 feature list has to be already defined, and input to the function)\n",
    "            X_train = apply_l1_feature_selection(X_train,feature_vector_list[c])\n",
    "            \n",
    "        # perform a GridSearchCV in order to train a classifier for this antibiotic\n",
    "        grid = GridSearchCV(clf,param_grid=params,scoring='roc_auc',n_jobs=njobs,pre_dispatch='2*n_jobs', cv=n_cv, iid=False,return_train_score=True)\n",
    "        grid.fit(X_train, Y_train)\n",
    "\n",
    "        # print the best parameters (to detect edge values), and save that classifier\n",
    "        print('The best parameters are: ',grid.best_params_)\n",
    "        best_clf = grid.best_estimator_\n",
    "        best_classifiers.append(best_clf)\n",
    "        grid_list.append(grid)\n",
    "        \n",
    "        best_clf = np.where(grid.cv_results_['rank_test_score']==1)[0][0]\n",
    "        AUC_train.append(grid.cv_results_['mean_train_score'][best_clf])\n",
    "        AUC_valid.append(grid.cv_results_['mean_test_score'][best_clf])\n",
    "        \n",
    "        print('Train AUC: ',np.round(AUC_train[-1],4),' and validation AUC: ',np.round(AUC_valid[-1],4))\n",
    "        \n",
    "    avg_AUC_train = np.mean(AUC_train)\n",
    "    avg_AUC_valid = np.mean(AUC_valid)\n",
    "    print('\\n\\nThe average train AUC is',np.round(avg_AUC_train,4),'and the avg validation AUC is',np.round(avg_AUC_valid,4))\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print('\\nFull execution took ',np.round(t2-t1,1),'seconds')\n",
    "    print('\\nDONE!')\n",
    "    return best_classifiers, grid_list, AUC_train, AUC_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TuL9bXuR1WgQ"
   },
   "source": [
    "## Enable L1 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrWju-uI1WgQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open(path+'l1_best_clfs.data', 'rb') as filehandle:\n",
    "    l1_best_clfs = pickle.load(filehandle)\n",
    "with open(path+'l1_feat_list.data', 'rb') as filehandle:\n",
    "    l1_feat_list = pickle.load(filehandle)\n",
    "\n",
    "# to be applyied to each category\n",
    "def apply_l1_feature_selection(spectrum_train,vect): # vect is l1_feat_list[c]\n",
    "    new_spectrum = spectrum_train.copy(deep=True).iloc[:,vect]   \n",
    "    return new_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7O-PYbym19Xw"
   },
   "source": [
    "## save_clf  &  load_clf\n",
    "Let's implement these functions so that we can load previous results without need to perform try_clf on all executions of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QSBMVFl24bc"
   },
   "outputs": [],
   "source": [
    "def save_clf(savepath,filename,clf_list):\n",
    "  # filename must be without extension\n",
    "  if (savepath[-1] != '/'): savepath = savepath + '/'\n",
    "  with open(savepath+filename+'.data','wb') as filehandle:\n",
    "    pickle.dump(clf_list,filehandle)\n",
    "\n",
    "def load_clf(savepath,filename):\n",
    "  if (savepath[-1] != '/'): savepath = savepath + '/'\n",
    "  if os.path.isfile(savepath+filename+'.data'):\n",
    "    with open(savepath+filename+'.data','rb') as filehandle:\n",
    "      new_list = pickle.load(filehandle)\n",
    "    print('Loaded!')\n",
    "  else:\n",
    "    print('File not found')\n",
    "    new_list = []\n",
    "  return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a42wJsvK1WgQ"
   },
   "source": [
    "## Logistic regressor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "colab_type": "code",
    "id": "ckrFlIvk1WgQ",
    "outputId": "c657b30c-228e-4794-91e4-4954e3d1c322",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 1000.0}\n",
      "Train AUC:  0.9999  and validation AUC:  0.7788\n",
      "['AMIKACINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 100.0}\n",
      "Train AUC:  0.993  and validation AUC:  0.7325\n",
      "['AMOXI/CLAV']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 100.0}\n",
      "Train AUC:  0.9867  and validation AUC:  0.7553\n",
      "['CIPROFLOXACINO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 1000.0}\n",
      "Train AUC:  1.0  and validation AUC:  0.7483\n",
      "['CLINDAMICINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 0.01}\n",
      "Train AUC:  0.6433  and validation AUC:  0.6012\n",
      "['ERITROMICINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 100.0}\n",
      "Train AUC:  0.9739  and validation AUC:  0.6185\n",
      "['LEVOFLOXACINO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 10.0}\n",
      "Train AUC:  0.9412  and validation AUC:  0.7604\n",
      "['PENICILINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 0.1}\n",
      "Train AUC:  0.7671  and validation AUC:  0.6291\n",
      "['TOBRAMICINA']\n",
      "The best parameters are:  {'C': 100.0}\n",
      "Train AUC:  0.9928  and validation AUC:  0.7462\n",
      "\n",
      "\n",
      "The average train AUC is 0.922 and the avg validation AUC is 0.7078\n",
      "\n",
      "Full execution took  33.2 seconds\n",
      "\n",
      "DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Equipo\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1cf81552ccb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlr_best_clfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_AUC_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_AUC_test_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msave_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'logreg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_best_clfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1e6, solver='lbfgs',class_weight='balanced')\n",
    "params = {'C':10.**np.arange(-2,4)}\n",
    "lr_best_clfs, _, _, lr_AUC_train, lr_AUC_test_train = try_clf(clf,params,10)\n",
    "\n",
    "save_clf(savepath,'logreg',lr_best_clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvBNDaeY1WgQ"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lfa9U8nk1WgQ",
    "outputId": "88bfe082-5a0e-4dac-d0fa-ffa8b4281063",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n",
      "The best parameters are:  {'n_neighbors': 6}\n",
      "Train accuracy:  0.7985  and test_train accuracy:  0.7019\n",
      "Train AUC:  0.8732  and test_train AUC:  0.7306\n",
      "['AMIKACINA']\n",
      "Dropped  66\n",
      "Dropped  22\n",
      "The best parameters are:  {'n_neighbors': 4}\n",
      "Train accuracy:  0.8324  and test_train accuracy:  0.7561\n",
      "Train AUC:  0.8794  and test_train AUC:  0.7109\n",
      "['AMOXI/CLAV']\n",
      "The best parameters are:  {'n_neighbors': 6}\n",
      "Train accuracy:  0.7985  and test_train accuracy:  0.7019\n",
      "Train AUC:  0.8714  and test_train AUC:  0.7182\n",
      "['CIPROFLOXACINO']\n",
      "The best parameters are:  {'n_neighbors': 2}\n",
      "Train accuracy:  0.8641  and test_train accuracy:  0.7212\n",
      "Train AUC:  0.9467  and test_train AUC:  0.6756\n",
      "['CLINDAMICINA']\n",
      "The best parameters are:  {'n_neighbors': 20}\n",
      "Train accuracy:  0.7961  and test_train accuracy:  0.7788\n",
      "Train AUC:  0.7476  and test_train AUC:  0.6753\n",
      "['ERITROMICINA']\n",
      "The best parameters are:  {'n_neighbors': 22}\n",
      "Train accuracy:  0.665  and test_train accuracy:  0.6154\n",
      "Train AUC:  0.7218  and test_train AUC:  0.5922\n",
      "['LEVOFLOXACINO']\n",
      "Dropped  2\n",
      "Dropped  2\n",
      "The best parameters are:  {'n_neighbors': 2}\n",
      "Train accuracy:  0.8683  and test_train accuracy:  0.7157\n",
      "Train AUC:  0.9519  and test_train AUC:  0.6467\n",
      "['PENICILINA']\n",
      "The best parameters are:  {'n_neighbors': 7}\n",
      "Train accuracy:  0.9175  and test_train accuracy:  0.9038\n",
      "Train AUC:  0.8939  and test_train AUC:  0.7255\n",
      "['TOBRAMICINA']\n",
      "Dropped  61\n",
      "Dropped  21\n",
      "The best parameters are:  {'n_neighbors': 4}\n",
      "Train accuracy:  0.8291  and test_train accuracy:  0.747\n",
      "Train AUC:  0.8838  and test_train AUC:  0.7587\n",
      "\n",
      "\n",
      "The average train AUC is 0.8633 and the avg test_train AUC is 0.6926\n",
      "\n",
      "Full execution took  174.4 seconds\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "params = {'n_neighbors':np.arange(1,30)}\n",
    "knn_best_clfs, _, _, knn_AUC_train, knn_AUC_test_train = try_clf(clf,params,10)\n",
    "\n",
    "save_clf(savepath,'knn',knn_best_clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr5mVGPb1WgQ"
   },
   "source": [
    "## SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvwhbPNC1WgQ",
    "outputId": "1357b8e3-0354-4295-e6f4-0f1f8a713ad9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n",
      "The best parameters are:  {'C': 10.0}\n",
      "Train accuracy:  0.8981  and test_train accuracy:  0.7404\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9479  and test_train AUC:  0.7719\n",
      "['AMIKACINA']\n",
      "Dropped  66\n",
      "Dropped  22\n",
      "The best parameters are:  {'C': 10.0}\n",
      "Train accuracy:  0.8786  and test_train accuracy:  0.7561\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9334  and test_train AUC:  0.7964\n",
      "['AMOXI/CLAV']\n",
      "The best parameters are:  {'C': 100.0}\n",
      "Train accuracy:  0.949  and test_train accuracy:  0.7115\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9856  and test_train AUC:  0.7711\n",
      "['CIPROFLOXACINO']\n",
      "The best parameters are:  {'C': 10.0}\n",
      "Train accuracy:  0.9053  and test_train accuracy:  0.7404\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9506  and test_train AUC:  0.7836\n",
      "['CLINDAMICINA']\n",
      "The best parameters are:  {'C': 1000.0}\n",
      "Train accuracy:  0.9903  and test_train accuracy:  0.6923\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9943  and test_train AUC:  0.6256\n",
      "['ERITROMICINA']\n",
      "The best parameters are:  {'C': 10000.0}\n",
      "Train accuracy:  0.9951  and test_train accuracy:  0.7788\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9971  and test_train AUC:  0.7977\n",
      "['LEVOFLOXACINO']\n",
      "Dropped  2\n",
      "Dropped  2\n",
      "The best parameters are:  {'C': 100.0}\n",
      "Train accuracy:  0.9659  and test_train accuracy:  0.7353\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9886  and test_train AUC:  0.7806\n",
      "['PENICILINA']\n",
      "The best parameters are:  {'C': 1000.0}\n",
      "Train accuracy:  1.0  and test_train accuracy:  0.8365\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  1.0  and test_train AUC:  0.5872\n",
      "['TOBRAMICINA']\n",
      "Dropped  61\n",
      "Dropped  21\n",
      "The best parameters are:  {'C': 1000.0}\n",
      "Train accuracy:  0.9886  and test_train accuracy:  0.7711\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9946  and test_train AUC:  0.8721\n",
      "\n",
      "\n",
      "The average train AUC is 0.9769 and the avg test_train AUC is 0.754\n",
      "\n",
      "Full execution took  172.0 seconds\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', class_weight='balanced')\n",
    "params = {'C':10.**np.arange(-1,6)}\n",
    "linear_SVM_best_clfs, _, _, linear_SVM_AUC_train, linear_SVM_AUC_test_train = try_clf(clf,params,10)\n",
    "save_clf(savepath,'linear_SVM',linear_SVM_best_clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PbxoOZt1WgQ"
   },
   "source": [
    "## SVM - Polynomial\n",
    "*It can not be done, the huge amount of features makes it computationally unfeasible*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbOQnJZW1WgQ"
   },
   "source": [
    "## SVM - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVD18aJB1WgQ",
    "outputId": "ec35add5-91ac-471a-886d-162eb59ec655",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n",
      "The best parameters are:  {'C': 100.0, 'gamma': 0.1}\n",
      "Train accuracy:  0.9587  and test_train accuracy:  0.7308\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9842  and test_train AUC:  0.8209\n",
      "['AMIKACINA']\n",
      "Dropped  66\n",
      "Dropped  22\n",
      "The best parameters are:  {'C': 1000.0, 'gamma': 0.1}\n",
      "Train accuracy:  0.9855  and test_train accuracy:  0.7805\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9935  and test_train AUC:  0.823\n",
      "['AMOXI/CLAV']\n",
      "The best parameters are:  {'C': 100.0, 'gamma': 0.1}\n",
      "Train accuracy:  0.9563  and test_train accuracy:  0.75\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9824  and test_train AUC:  0.7957\n",
      "['CIPROFLOXACINO']\n",
      "The best parameters are:  {'C': 100.0, 'gamma': 0.1}\n",
      "Train accuracy:  0.9539  and test_train accuracy:  0.7692\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.98  and test_train AUC:  0.834\n",
      "['CLINDAMICINA']\n",
      "The best parameters are:  {'C': 100.0, 'gamma': 1.0}\n",
      "Train accuracy:  0.9903  and test_train accuracy:  0.7404\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9948  and test_train AUC:  0.7233\n",
      "['ERITROMICINA']\n",
      "The best parameters are:  {'C': 10000.0, 'gamma': 0.001}\n",
      "Train accuracy:  0.8835  and test_train accuracy:  0.7308\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9476  and test_train AUC:  0.7432\n",
      "['LEVOFLOXACINO']\n",
      "Dropped  2\n",
      "Dropped  2\n",
      "The best parameters are:  {'C': 1000.0, 'gamma': 0.01}\n",
      "Train accuracy:  0.9463  and test_train accuracy:  0.7353\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.982  and test_train AUC:  0.8127\n",
      "['PENICILINA']\n",
      "The best parameters are:  {'C': 100.0, 'gamma': 1.0}\n",
      "Train accuracy:  1.0  and test_train accuracy:  0.8942\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  1.0  and test_train AUC:  0.6351\n",
      "['TOBRAMICINA']\n",
      "Dropped  61\n",
      "Dropped  21\n",
      "The best parameters are:  {'C': 1000.0, 'gamma': 0.1}\n",
      "Train accuracy:  0.9858  and test_train accuracy:  0.7952\n",
      "Using decision_function instead of predict_proba\n",
      "Train AUC:  0.9908  and test_train AUC:  0.8344\n",
      "\n",
      "\n",
      "The average train AUC is 0.9839 and the avg test_train AUC is 0.7803\n",
      "\n",
      "Full execution took  843.8 seconds\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced')\n",
    "\n",
    "C_vector = 10. ** np.arange(-1,6)\n",
    "gamma_vector = 10. ** np.arange(-4,1)\n",
    "params = {'C':C_vector, 'gamma':gamma_vector}\n",
    "\n",
    "rbf_SVM_best_clfs, _, _, rbf_SVM_AUC_train, rbf_SVM_AUC_test_train = try_clf(clf,params,10)\n",
    "\n",
    "save_clf(savepath,'rbf_SVM',rbf_SVM_best_clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VhKvjZsG1WgQ"
   },
   "source": [
    "## RF with balanced classes and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZM-44jPf1WgQ",
    "outputId": "f127dea3-c122-4912-a69f-c7ac46f24a2d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n",
      "The best parameters are:  {'max_depth': 6, 'n_estimators': 50}\n",
      "Train accuracy:  0.9709  and test_train accuracy:  0.7404\n",
      "Train AUC:  0.9965  and test_train AUC:  0.7143\n",
      "['AMIKACINA']\n",
      "Dropped  66\n",
      "Dropped  22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8a1f9461896e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf_best_clfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_AUC_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_AUC_test_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msave_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rf_cv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_best_clfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-df0bed1db8ee>\u001b[0m in \u001b[0;36mtry_clf\u001b[1;34m(clf, params, n_cv)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# perform a GridSearchCV in order to train a classifier for this antibiotic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# print the best parameters (to detect edge values), and save that classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[0mis_multimetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_safe_split\u001b[1;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0mX_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mX_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;31m# Pandas Dataframes and Series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;31m# Cython typed memoryviews internally used in pandas do not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2146\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;31m# a single integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2128\u001b[0m         \"\"\"\n\u001b[0;32m   2129\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2131\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m             \u001b[1;31m# re-raise with different error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[1;32m-> 3604\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3605\u001b[0m         )\n\u001b[0;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1393\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Indices must be nonzero and less than the axis length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m         return self.reindex_indexer(\n\u001b[0;32m   1397\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Unable to fill values because {0} cannot contain NA\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m             \u001b[0mtaken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced',min_samples_split=5)\n",
    "params = {'n_estimators':[10,30,50,70,150,250],'max_depth':np.arange(1,50)}\n",
    "rf_best_clfs, _, _, rf_AUC_train, rf_AUC_test_train = try_clf(clf,params)\n",
    "save_clf(savepath,'rf_cv',rf_best_clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-Ns5dD61WgQ",
    "scrolled": true
   },
   "source": [
    "## Real Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRs5VKt91WgQ",
    "outputId": "498cf025-b4e5-485d-8ce8-c76d58466e72",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9951  and test_train accuracy:  0.8173\n",
      "Train AUC:  1.0  and test_train AUC:  0.8356\n",
      "['AMIKACINA']\n",
      "Dropped  66\n",
      "Dropped  22\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9884  and test_train accuracy:  0.6707\n",
      "Train AUC:  0.9997  and test_train AUC:  0.6923\n",
      "['AMOXI/CLAV']\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9951  and test_train accuracy:  0.7308\n",
      "Train AUC:  0.9999  and test_train AUC:  0.7553\n",
      "['CIPROFLOXACINO']\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9879  and test_train accuracy:  0.7212\n",
      "Train AUC:  0.9997  and test_train AUC:  0.7125\n",
      "['CLINDAMICINA']\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9903  and test_train accuracy:  0.7692\n",
      "Train AUC:  0.9997  and test_train AUC:  0.6755\n",
      "['ERITROMICINA']\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9951  and test_train accuracy:  0.7212\n",
      "Train AUC:  0.9999  and test_train AUC:  0.7142\n",
      "['LEVOFLOXACINO']\n",
      "Dropped  2\n",
      "Dropped  2\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9902  and test_train accuracy:  0.7059\n",
      "Train AUC:  0.9998  and test_train AUC:  0.7467\n",
      "['PENICILINA']\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  1.0  and test_train accuracy:  0.9038\n",
      "Train AUC:  1.0  and test_train AUC:  0.733\n",
      "['TOBRAMICINA']\n",
      "Dropped  61\n",
      "Dropped  21\n",
      "The best parameters are:  {'n_estimators': 500}\n",
      "Train accuracy:  0.9886  and test_train accuracy:  0.7349\n",
      "Train AUC:  0.9997  and test_train AUC:  0.7569\n",
      "\n",
      "\n",
      "The average train AUC is 0.9998 and the avg test_train AUC is 0.7358\n",
      "\n",
      "Full execution took  4445.8 seconds\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2)) # we can change that\n",
    "params = {'n_estimators':[500]}\n",
    "ab_best_clfs, _, _, ab_AUC_train, ab_AUC_test_train = try_clf(clf,params)\n",
    "save_clf(savepath,'ab_sklearn_cv',ab_best_clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own Real AdaBoost\n",
    "The one coded for Homework 2. After some trials, it seems to work much better than the sklearn method. The following code is a modification. Moreover, the number of learners will be set to 500 as in some test (up to 2.000 learners) that seemed a good point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "class OurAdaBoostEnsemble():\n",
    "    def __init__(self,T):\n",
    "        self.T = T\n",
    "\n",
    "    def fit(self,X_train, Y_train):\n",
    "        T = self.T\n",
    "        \n",
    "        Y_train[Y_train==0] = -1 # change labels 0 to -1, if needed\n",
    "\n",
    "        alpha = np.zeros((T,1))\n",
    "        Dt_all = np.zeros((T,X_train.shape[0]))\n",
    "        Dt_all[0,:] = np.ones((1,X_train.shape[0])) / X_train.shape[0]  # Initialize all weights as 1 / n_samples\n",
    "\n",
    "        outputs_train = np.zeros((T,Y_train.shape[0]))\n",
    "\n",
    "        tree_list = []\n",
    "\n",
    "        for i in range(T):\n",
    "            mytree = DecisionTreeClassifier(max_depth=2)\n",
    "            mytree.fit(X_train,Y_train,sample_weight=Dt_all[i,:])\n",
    "            tree_list.append(mytree)\n",
    "\n",
    "            # For real-valued predictions:\n",
    "            outputs_train[i,:] = np.dot(mytree.predict_proba(X_train),mytree.classes_)\n",
    "            \n",
    "            # Get gamma and alpha_i values\n",
    "            gamma = np.dot(Dt_all[i,:],np.multiply(outputs_train[i,:],Y_train))\n",
    "            alpha[i] = 0.5 * np.log((1+gamma)/(1-gamma))\n",
    "\n",
    "            # Update emphasis function (except if in the last iteration)\n",
    "            if (i < T-1):\n",
    "                emphasis = np.multiply(Dt_all[i,:],np.exp(-1*alpha[i]*np.multiply(outputs_train[i,:],Y_train)))\n",
    "                Dt_all[i+1,:] = emphasis / np.sum(emphasis) # normalize\n",
    "\n",
    "        # save neccessary parameters for the other methods\n",
    "        self.T = T\n",
    "        self.alpha = alpha\n",
    "        self.tree_list = tree_list\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        outputs = np.zeros((self.T,X.shape[0]))\n",
    "        for t in range(self.T):\n",
    "            mytree = self.tree_list[t]\n",
    "            outputs[t,:] = mytree.predict_proba(X)[:,-1].T\n",
    "        f = np.sum(np.multiply(outputs,self.alpha),axis=0).reshape((-1,1))\n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvPF1Gd41WgQ"
   },
   "source": [
    "# 5-fold cross-validation of resulting classifiers\n",
    "We have already used cross-validation to select the most suitable hyperparameters for the classifiers. Now, let's do a 10-fold split in order to see the general performance and std of each classifier over each of the \"test\" splits, in order to choose the best performing ones for each antibiotic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_bKz5Wf1WgQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFold 1 finished!\n",
      "\tFold 2 finished!\n",
      "\tFold 3 finished!\n",
      "\tFold 4 finished!\n",
      "\tFold 5 finished!\n",
      "\tFold 6 finished!\n",
      "\tFold 7 finished!\n",
      "\tFold 8 finished!\n",
      "\tFold 9 finished!\n",
      "\tFold 10 finished!\n",
      "Category OXACILINA finished!\n",
      "\n",
      "Dropped  88\n",
      "\tFold 1 finished!\n",
      "\tFold 2 finished!\n",
      "\tFold 3 finished!\n",
      "\tFold 4 finished!\n",
      "\tFold 5 finished!\n",
      "\tFold 6 finished!\n",
      "\tFold 7 finished!\n",
      "\tFold 8 finished!\n",
      "\tFold 9 finished!\n",
      "\tFold 10 finished!\n",
      "Category AMIKACINA finished!\n",
      "\n",
      "\tFold 1 finished!\n",
      "\tFold 2 finished!\n",
      "\tFold 3 finished!\n",
      "\tFold 4 finished!\n",
      "\tFold 5 finished!\n",
      "\tFold 6 finished!\n",
      "\tFold 7 finished!\n",
      "\tFold 8 finished!\n",
      "\tFold 9 finished!\n",
      "\tFold 10 finished!\n",
      "Category AMOXI/CLAV finished!\n",
      "\n",
      "\tFold 1 finished!\n",
      "\tFold 2 finished!\n",
      "\tFold 3 finished!\n",
      "\tFold 4 finished!\n",
      "\tFold 5 finished!\n",
      "\tFold 6 finished!\n",
      "\tFold 7 finished!\n",
      "\tFold 8 finished!\n",
      "\tFold 9 finished!\n",
      "\tFold 10 finished!\n",
      "Category CIPROFLOXACINO finished!\n",
      "\n",
      "\tFold 1 finished!\n",
      "\tFold 2 finished!\n",
      "\tFold 3 finished!\n",
      "\tFold 4 finished!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-56dafe69220c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mX_test_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mY_test_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_best_clfs_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"predict_proba\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mpred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# only take last column, the prob of Y = +1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \"\"\"\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "spectrum_full_train = spectrum_in_bins(data,m,M,bin_size)\n",
    "targets_full_train = targets.copy(deep=True)\n",
    "\n",
    "N = 10\n",
    "ab_ours = [OurAdaBoostEnsemble(T=500)]*9\n",
    "list_of_best_clfs_list = [lr_best_clfs,knn_best_clfs,rbf_SVM_best_clfs,linear_SVM_best_clfs,ab_best_clfs,ab_ours]\n",
    "labs = ['LogReg','KNN','RBF SVM','Linear SVM','AdaBoost','Our AdaBoost']\n",
    "categories = targets.columns[:]\n",
    "test_aucs = np.zeros((len(categories),len(list_of_best_clfs_list),N))   # The dimensions are cat x type of clf x fold\n",
    "train_aucs = np.zeros((len(categories),len(list_of_best_clfs_list),N))\n",
    "      \n",
    "cv = StratifiedKFold(n_splits=N, random_state=123, shuffle=True)\n",
    "\n",
    "for c, cat in enumerate(categories):\n",
    "    X, Y = clean_nan_samples(spectrum_full_train,targets_full_train, c, cat)  \n",
    "    \n",
    "    for (train, test), i in zip(cv.split(X, Y), range(N)):\n",
    "        X_train = X.iloc[train]; Y_train = Y[train];\n",
    "        X_test_train = X.iloc[test]; Y_test_train = Y[test];\n",
    "        for nclf, l in enumerate(list_of_best_clfs_list):\n",
    "            clf = l[c].fit(X_train,Y_train)\n",
    "            if callable(getattr(clf,\"predict_proba\",None)):\n",
    "                pred_train = clf.predict_proba(X_train)[:,-1] # only take last column, the prob of Y = +1\n",
    "                pred_test = clf.predict_proba(X_test_train)[:,-1]\n",
    "            else:\n",
    "                pred_train = clf.decision_function(X_train)\n",
    "                pred_test = clf.decision_function(X_test_train) \n",
    "            train_aucs[c,nclf,i] = roc_auc_score(Y_train, pred_train)\n",
    "            test_aucs[c,nclf,i] = roc_auc_score(Y_test_train, pred_test)\n",
    "        print('\\tFold '+str(i+1)+' finished!')\n",
    "    print('Category '+cat+' finished!\\n')\n",
    "\n",
    "# The dimensions are cat x type of clf x fold\n",
    "mean_test_auc = np.mean(test_aucs,axis=2)\n",
    "std_test_auc  = np.std( test_aucs,axis=2)\n",
    "print('\\n\\nDONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "col_names = targets.columns.values\n",
    "for i in range(len(list_of_best_clfs_list)):\n",
    "    plt.errorbar(col_names,mean_test_auc[:,i],std_test_auc[:,i],label=labs[i])\n",
    "plt.title('AUC for test_train set with '+str(N)+' fold testing')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zo3Fcxti1WgQ"
   },
   "outputs": [],
   "source": [
    "# save all of this\n",
    "mydict = {'listoflist':list_of_best_clfs_list,'labels':labs,'AUC_test':test_aucs}\n",
    "save_clf(savepath,'dict_bs5_allclfs_10fold',mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many support vectors means that the model is overfitted\n",
    "N = len(X_train) # total number of samples\n",
    "\n",
    "for c, cat in enumerate(categories):\n",
    "    print('Linear SVM:')\n",
    "    n_sv = len(linear_SVM_best_clfs[c].support_)\n",
    "    print('Proportion of support vectors: ',n_sv*100/N,'%')\n",
    "\n",
    "for c, cat in enumerate(categories):\n",
    "    print('\\nRBF SVM:')\n",
    "    n_sv = len(rbf_SVM_best_clfs[c].support_)\n",
    "    print('Proportion of support vectors: ',n_sv*100/N,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7eKQpWr1WgQ"
   },
   "source": [
    "# Generate final results in CSV format\n",
    "From \"Jagger_4_GenerateCSV_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIIKsycJ1WgQ"
   },
   "outputs": [],
   "source": [
    "def get_unique_spectre(spectre, df):\n",
    "  # Include the ID_sample column for the group_by\n",
    "  spectre['ID_sample'] = df.ID_sample\n",
    "  # MEAN OF THE SPECTRE\n",
    "  spectre = spectre.groupby('ID_sample').mean().reset_index()\n",
    "  return spectre\n",
    "\n",
    "def generate_csv_from_clf(clf_list, path, path_results, file_name):\n",
    "  # classifiers must be provided with parameters, and in a list [clf_antibiotic0, clf_antibiotic1, ...]\n",
    "  # spectrum and targets full train (containing all training points) will be used for training the clfs in clf list\n",
    "  # df_test must be provided as loaded from the file\n",
    "\n",
    "  # read all data from files\n",
    "  zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "  df_full_train = _pickle.loads(zf.open('TrainData.pkl').read());   zf.close()\n",
    "\n",
    "  zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "  df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read());   zf.close()\n",
    "\n",
    "  # Process test df to get UNIQUE samples and convert to spectrum\n",
    "\n",
    "  # df_unique_test = df_test.drop_duplicates(subset='ID_sample')\n",
    "\n",
    "  spectrum_test_forcsv = spectrum_in_bins(df_test,m,M,bin_size)\n",
    "  spectrum_test_forcsv = get_unique_spectre(spectrum_test_forcsv, df_test)\n",
    "\n",
    "  # Process train set to later train the clfs\n",
    "  spectrum_full_train = spectrum_in_bins(df_full_train.iloc[:,-2:],m,M,bin_size)\n",
    "  targets_full_train  = df_full_train.iloc[:,1:-2]  \n",
    "\n",
    "  # read the submission example file\n",
    "  df_submission = pd.read_csv(path+'SubmissionSample.csv') \n",
    "  categories = df_submission.columns[1:]\n",
    "  df_submission['ID']= spectrum_test_forcsv['ID_sample'].values\n",
    "  # To eliminate the ID_sample from the spectrum\n",
    "  spectrum_test_forcsv = spectrum_test_forcsv.drop(columns=['ID_sample'])\n",
    "  for c, cat in enumerate(categories): \n",
    "      # clean NaN values\n",
    "      X_train, Y_train = clean_nan_samples(spectrum_full_train,targets_full_train, c, cat)\n",
    "\n",
    "      # fit the classifier\n",
    "      clf_base = clf_list[c].fit(X_train,Y_train)\n",
    "      # Compute its test prestiction and save this output\n",
    "      o_test = clf_base.predict_proba(spectrum_test_forcsv)[:,1]\n",
    "      df_submission[cat] = o_test\n",
    "\n",
    "  # Save the dataframe with the predicted outputs\n",
    "  df_submission = df_submission.set_index('ID')\n",
    "  df_submission.to_csv(path_results + file_name + '.csv')\n",
    "  print('DONE!')\n",
    "  return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdKC-t7m1Wh0"
   },
   "outputs": [],
   "source": [
    "# Let's create manually a list of good classifiers\n",
    "clf_oxalacina       = #\n",
    "clf_amikacina       = #\n",
    "clf_amoxiclav       = #\n",
    "clf_ciprofloxacino  = #\n",
    "clf_clindamicina    = #\n",
    "clf_eritromicina    = #\n",
    "clf_levofloxacino   = #\n",
    "clf_penicilina      = #\n",
    "clf_tobramicina     = #\n",
    "\n",
    "clf_list = [clf_oxalacina, clf_amikacina, clf_amoxiclav, clf_ciprofloxacino, clf_clindamicina,\n",
    "            clf_eritromicina, clf_levofloxacino, clf_penicilina, clf_tobramicina]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qD_GFf9gFSNM"
   },
   "outputs": [],
   "source": [
    "savepath = '/content/drive/My Drive/Colab Notebooks/Kaggle/Kaggle classifiers/bin size 10'\n",
    "clf_list_bs10 = load_clf(savepath,'logreg')\n",
    "savepath = '/content/drive/My Drive/Colab Notebooks/Kaggle/Kaggle classifiers/bin size 50'\n",
    "clf_list_bs50 = load_clf(savepath,'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "ZjM75A1_1Wh0",
    "outputId": "e36dc954-7928-423f-fb4a-0ae6f0bd671d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped  88\n",
      "Dropped  4\n",
      "Dropped  82\n",
      "DONE!\n",
      "File: logreg_bs10 has been successfully generated\n"
     ]
    }
   ],
   "source": [
    "name = 'logreg_bs10'\n",
    "df_submission = generate_csv_from_clf(clf_list_bs10,path,path_results, name)\n",
    "print('File: '+name+' has been successfully generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "CkB_6IJgFoU0",
    "outputId": "1dcb01c4-94fa-42ef-c6ad-b6e1bfb63b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped  88\n",
      "Dropped  4\n",
      "Dropped  82\n",
      "DONE!\n",
      "File: logreg_bs50 has been successfully generated\n"
     ]
    }
   ],
   "source": [
    "name = 'logreg_bs50'\n",
    "df_submission = generate_csv_from_clf(clf_list_bs50,path,path_results, name)\n",
    "print('File: '+name+' has been successfully generated')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Jagger_3_TryingDifferentClassifiers_v4_retesting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
