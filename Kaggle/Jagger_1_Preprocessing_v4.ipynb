{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4ilVujtlVoz"
   },
   "source": [
    "# Preprocessing\n",
    "First, let's focus on correctly preprocessing the data. Probably this is the key for a successful classification later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6v5BFLylVo6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import _pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMMXC8DRlVpN"
   },
   "outputs": [],
   "source": [
    "path = \"D:/GitHub/Machine-Learning/Kaggle/\"\n",
    "# path = \"C:/Users/Javi/Documents/GitHub/Machine-Learning/Kaggle/\"\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "df_train = _pickle.loads(zf.open('TrainData.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read())\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCIJe1kllVp0"
   },
   "source": [
    "As we can see, the data contains different columns:\n",
    "* **ID**: Just the basic index per row\n",
    "* **ID_sample**: the ID of the physical sample this is coming from. We should think about how to use different experimental results coming from the same sample. For the moment being, let's just treat them as different samples.\n",
    "* **Different antibiotics**: data of whether the sample is resistant of not to 9 different antibiotics. Our goal is to predict separately these resistances (one binary classifier for each antibiotic).\n",
    "* **MZ coordinate**: mass spectrometry is defined over the so-called m/z spectra. Therefore, this constitutes the X axis of the plot.\n",
    "* **Intensity**: Intensity of the spectra at each point (Y values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpTu1PivlVp2"
   },
   "source": [
    "Literature:\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6088204/\n",
    "\n",
    "Basically, it seems that MALDI TOF MS is routinely used for sample identification. Also, it is used for susceptibility testing (antibiotic resistance classification), mainly using the peaks of the spectra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPr-4VlelVqB"
   },
   "source": [
    "### Preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSMrVvpilVqF"
   },
   "source": [
    "#### Eliminate NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan_samples(spectrum,targets, c, cat):\n",
    "# if there are any NaN values, we should remove those samples\n",
    "    if (targets[cat].isnull().sum() > 0).all(): \n",
    "#         print('There are NaN values in',cat)\n",
    "        merged = pd.concat([spectrum , targets],axis=1,copy=True)\n",
    "        clean = merged.dropna(subset=[cat])\n",
    "#         print('Dropped ',len(merged)-len(clean))\n",
    "\n",
    "        Y = clean.iloc[:,-9+c].to_numpy().reshape(-1,)\n",
    "        X = clean.iloc[:,:-9]\n",
    "\n",
    "    else:\n",
    "        Y = targets.iloc[:,c].to_numpy().reshape(-1,)\n",
    "        X = spectrum.copy(deep=True)\n",
    "    return X , Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrum in bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbmznxBdlVrX"
   },
   "outputs": [],
   "source": [
    "def spectrum_in_bins(df,m,M,bin_size):\n",
    "    # Now, let's define the mz ranges, and the label associated to each of them (the mean of the limiting values of each bin)\n",
    "    range_min = []; range_max = []; range_label = [];\n",
    "    for mz in range(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_label.append(np.mean([range_min[-1],range_max[-1]]).astype(int))\n",
    "\n",
    "\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    for idx in range(N): \n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        idx_data_in_bins = np.zeros((1,L))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                idx_data_in_bins[0,i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum\n",
    "                idx_data_in_bins[0,i] = 0   \n",
    "\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins[0,:] = idx_data_in_bins[0,:] / np.max(idx_data_in_bins[0,:])\n",
    "        \n",
    "        \n",
    "        all_data[idx,:] = idx_data_in_bins\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_label, index = df.index)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qL9EuMJ1lVr4"
   },
   "source": [
    "### Data split\n",
    "Separate data in data and targets, as well as in train, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCcsP5XJlVr6",
    "outputId": "ad8df050-6d2d-4934-9aee-d569629adb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 412 and test_train samples: 104\n"
     ]
    }
   ],
   "source": [
    "# Extract data (spectra) and targets of the df_train set\n",
    "data = df_train.iloc[:,-2:]\n",
    "targets = df_train.iloc[:,1:-2]\n",
    "\n",
    "m = 2000; M = 20000; \n",
    "bin_size = 50;\n",
    "\n",
    "# Then, split into a train and test_train set\n",
    "data_train, data_test_train, targets_train, targets_test_train = train_test_split(data, targets, test_size=0.2, random_state=42) # split the data\n",
    "print('Training samples: '+str(len(data_train))+' and test_train samples: ' + str(len(data_test_train)) )\n",
    "\n",
    "# apply the bins to all spectra, so that our feature space becomes the same for all samples (make them regular, all the same)\n",
    "spectrum_train = spectrum_in_bins(data_train,m,M,bin_size)\n",
    "spectrum_test_train = spectrum_in_bins(data_test_train,m,M,bin_size)\n",
    "print('Spectrum regularized!')\n",
    "# these spectrum_... are our X for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N557Ymedlknf"
   },
   "source": [
    "# Unify spectre function\n",
    "\n",
    "\n",
    "Now lets unify the spectre of the samples so we get the 112 samples with different approaches on spectre treatment: mean, median, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26743,
     "status": "ok",
     "timestamp": 1577185727115,
     "user": {
      "displayName": "JESUS HERRERA LOPEZ",
      "photoUrl": "",
      "userId": "16448325777196326447"
     },
     "user_tz": -60
    },
    "id": "laCoOrT9lVts",
    "outputId": "077e6167-b7ce-4ad0-80c8-0ee2c23399b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Take the data from Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "path = \"/content/drive/My Drive/Colab Notebooks/Kaggle/Kaggle_data/\"\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "df_train = _pickle.loads(zf.open('TrainData.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read())\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1098,
     "status": "ok",
     "timestamp": 1577185742339,
     "user": {
      "displayName": "JESUS HERRERA LOPEZ",
      "photoUrl": "",
      "userId": "16448325777196326447"
     },
     "user_tz": -60
    },
    "id": "PbR6p4F_lVtw",
    "outputId": "d7f3e39a-290a-4b7e-f7d4-7879f25c0920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 3)\n",
      "112\n",
      "(516, 12)\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(df_test))\n",
    "print(df_test['ID_sample'].nunique())\n",
    "print(np.shape(df_train))\n",
    "print(df_train['ID_sample'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1j6354HlVt2"
   },
   "outputs": [],
   "source": [
    "def spectrum_in_bins(df,m,M,bin_size):\n",
    "    # Now, let's define the mz ranges, and the label associated to each of them (the mean of the limiting values of each bin)\n",
    "    range_min = []; range_max = []; range_label = [];\n",
    "    for mz in range(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_label.append(np.mean([range_min[-1],range_max[-1]]).astype(int))\n",
    "\n",
    "\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    \n",
    "\n",
    "    for idx in range(N): \n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        idx_data_in_bins = np.zeros((1,L))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                idx_data_in_bins[0,i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum\n",
    "                idx_data_in_bins[0,i] = 0   \n",
    "\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins[0,:] = idx_data_in_bins[0,:] / np.max(idx_data_in_bins[0,:])\n",
    "        \n",
    "        \n",
    "        # THIS HAS BEEN CHANGED TO MAKE THE TEST SPECTRUM\n",
    "        all_data[idx,:] = idx_data_in_bins\n",
    "\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_label, index = df.index)\n",
    "    new_df['ID_sample'] = df.ID_sample\n",
    "    cols = new_df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    new_df = new_df[cols]\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4WogA6UoS4u"
   },
   "outputs": [],
   "source": [
    "# Change the way the spectre is handled: Now is MEAN\n",
    "# Could be changed to the highest value of both or the lowest, susceptible to changes\n",
    "\n",
    "def get_unique_spectre(spectre):\n",
    "  \n",
    "  # MEAN OF THE SPECTRE\n",
    "  spectre = spectre.groupby('ID_sample').mean().reset_index()\n",
    "  return spectre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uR_6PZ9Z9wdD"
   },
   "outputs": [],
   "source": [
    "# Change the way the targets are handled: Now is the MAX value\n",
    "\n",
    "def get_unique_target(target):\n",
    "\n",
    "  # MAX value of the target\n",
    "  target = target.groupby('ID_sample').max().reset_index()\n",
    "  return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8288,
     "status": "ok",
     "timestamp": 1577189574024,
     "user": {
      "displayName": "JESUS HERRERA LOPEZ",
      "photoUrl": "",
      "userId": "16448325777196326447"
     },
     "user_tz": -60
    },
    "id": "4RDg5EAzlVt8",
    "outputId": "75aded9a-6695-42f8-fe7e-795be1bbae39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrum regularized!\n"
     ]
    }
   ],
   "source": [
    "# Extract data (spectra) and targets of the df_train set\n",
    "data = df_train.iloc[:,-2:]\n",
    "targets = df_train.iloc[:,:-2]\n",
    "\n",
    "m = 2000; M = 20000; \n",
    "bin_size = 50;\n",
    "\n",
    "# apply the bins to all spectra, so that our feature space becomes the same for all samples (make them regular, all the same)\n",
    "spectrum_train = spectrum_in_bins(df_train,m,M,bin_size)\n",
    "spectrum_test_train = spectrum_in_bins(df_test,m,M,bin_size)\n",
    "print('Spectrum regularized!')\n",
    "# these spectrum_... are our X for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNeC4biJ_xTC"
   },
   "outputs": [],
   "source": [
    "new_test_spectrum = get_unique_spectre(spectrum_train)\n",
    "new_target = get_unique_target(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWD8fR0BsZ5i"
   },
   "outputs": [],
   "source": [
    "# TESTEO\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=1e6, solver='lbfgs')\n",
    "params = {'C':10.**np.arange(-5,5)}\n",
    "lr_best_clfs, _, _, lr_AUC_train, lr_AUC_test_train = try_clf_csv(clf,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is already finished in Jagger_4_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Jagger_1_Preprocessing_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
