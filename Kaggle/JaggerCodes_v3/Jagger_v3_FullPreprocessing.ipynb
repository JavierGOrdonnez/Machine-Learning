{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import _pickle\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import time\n",
    "import os\n",
    "import peakutils\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "\n",
    "from ourfunctions_v3 import clean_nan_samples, remove_noise, interpolate_spectra, spectrum_in_bins_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Preprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2000; M = 12000; \n",
    "bin_size = 5\n",
    "step_size = 1; # interpolation step size\n",
    "\n",
    "path = \"D:/GitHub/Machine-Learning/Kaggle/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample 339  eliminated\n",
      "Training sample 490  eliminated\n"
     ]
    }
   ],
   "source": [
    "savepath = path + 'Kaggle classifiers/bin size 5/'\n",
    "path_results = path + 'Kaggle_results/'\n",
    "\n",
    "ncpu = os.cpu_count()\n",
    "if (ncpu>2): njobs = ncpu - 2; \n",
    "else: njobs = 1;\n",
    "    \n",
    "zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "df_train = _pickle.loads(zf.open('TrainData.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "df_train = remove_noise(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data in test and train\n",
    "Also binning spectrum, normalize and remove baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 411 and test_train samples: 103\n",
      "Spectrum interpolated!\n"
     ]
    }
   ],
   "source": [
    "# Extract data (spectra) and targets of the df_train set\n",
    "data = df_train.iloc[:,-2:]\n",
    "targets = df_train.iloc[:,1:-2]\n",
    "\n",
    "# Then, split into a train and test_train set\n",
    "data_train, data_test_train, targets_train, targets_test_train = train_test_split(data, targets, test_size=0.2, random_state=0) # split the data\n",
    "print('Training samples: '+str(len(data_train))+' and test_train samples: ' + str(len(data_test_train)) )\n",
    "\n",
    "# apply the bins to all spectra, so that our feature space becomes the same for all samples (make them regular, all the same)\n",
    "spectrum_train = spectrum_in_bins_3(data_train,m,M,bin_size)\n",
    "spectrum_test_train = spectrum_in_bins_3(data_test_train,m,M,bin_size)\n",
    "print('Spectrum interpolated!')\n",
    "# these spectrum_... are our X for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak detection algorithms\n",
    "We can consider different peak detection algorithms:\n",
    "* Gaussian Mixture Model: although slower, it is supposedly more accurate and appropiate. When using a low count level, the algorithm is fast and detects most peaks. However, many times their mean is somehow displaced. This would need to be corrected by looking at the maximum value in the vicinity. On the other hand, when using a higher count level (smaller single sample value, and more elements in samples_vector), the algorithm takes much more time, and also BIC indicates much larger values of N_COMPONENTS than what it should, leading to detection of many false peaks.\n",
    "* PeakUtils peak detection: this function is actually working pretty well, although I think it is based on thresholding. Nonetheless, with a threshold of 0.05, is detecting very accurately most peaks and not giving too many false positives.\n",
    "* FindPeaksCWT is another option for peak detection, although more sensitive to window size. Yesterday, I found bin_size = 5 and window_width = 3 to be a good combination.\n",
    "\n",
    "In any case, after finding the peaks in the mean spectra, a new set of features should be built by getting the values of each spectrum at those positions (or nearby, in the case of inaccurate GMM). This will lead to a much lower number of features, and therefore to faster, less noisy classification. Anyway, a feature reduction step should be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's get the mean spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_spectrum = np.mean(spectrum_train.to_numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample_value = 0.001 \n",
    "# IMPORTANT: larger is less accurate in MZ but faster and less false positives\n",
    "\n",
    "samples_vector = []\n",
    "for i in range(len(mean_spectrum)):\n",
    "    count = np.round(mean_spectrum[i]/single_sample_value)\n",
    "    mz_coord = spectrum_train.columns.values[i]\n",
    "    for a in np.arange(count):\n",
    "        samples_vector.append(mz_coord)\n",
    "        \n",
    "samples_vector = np.asarray(samples_vector).reshape(-1,1)\n",
    "print('DONE!')\n",
    "print('There are %d samples' %len(samples_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: time consuming. To find optimal N. Works well for large single_sample_value (0.01), not for small ones (0.001).\n",
    "\n",
    "# BIC = []\n",
    "# n_components = np.arange(5,101,5)\n",
    "\n",
    "# for n in n_components:\n",
    "#     g = GMM(n_components = n,n_init=2)\n",
    "#     g.fit(samples_vector)\n",
    "#     BIC.append(g.bic(samples_vector))\n",
    "# plt.plot(n_components,BIC)\n",
    "# idx = np.argsort(BIC)\n",
    "# N = n_components[idx[0]]\n",
    "# print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40  # N = 40 should work quite well\n",
    "g = GMM(n_components = N,n_init=5)\n",
    "g.fit(samples_vector)\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(spectrum_train.columns.values,mean_spectrum)\n",
    "plt.plot(g.means_,g.weights_*g.n_components/5,'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: feature selection with some +- in MZ axis (+- 8 bin_size should do, that is, +- 8 points)\n",
    "# use this to get the final peak MZ coordinates. And then just take those values for all spectra.\n",
    "# It could also be useful for PeakUtils method, although with smaller margins (just 1 or 2 points to each side)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PeakUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = peakutils.peak.indexes(mean_spectrum)peaks = peakutils.peak.indexes(mean_spectrum,thres=0.05)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(mean_spectrum)\n",
    "plt.plot(peaks,mean_spectrum[peaks],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use previous function to get new feature set (peaks) for all samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
