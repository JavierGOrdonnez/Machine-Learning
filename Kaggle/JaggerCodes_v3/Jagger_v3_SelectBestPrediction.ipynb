{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that we have several (two) spectra per sample. Then, instead of averaging them or discarding one of them randomly, let's select those results which are closer to zero or one (with some sort of Gini index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import _pickle\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import time\n",
    "import os\n",
    "import peakutils\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2000; M = 12000; \n",
    "bin_size = 1;\n",
    "\n",
    "path = \"C:/Users/Javi/Documents/GitHub/Machine-Learning/Kaggle/\"\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "df_train = _pickle.loads(zf.open('TrainData.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read())\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_in_bins(df,m,M,bin_size):\n",
    "    # Now, let's define the mz ranges, and the label associated to each of them (the mean of the limiting values of each bin)\n",
    "    range_min = []; range_max = []; range_label = [];\n",
    "    for mz in range(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_label.append(np.mean([range_min[-1],range_max[-1]]).astype(int))\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    for idx in range(N): \n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        idx_data_in_bins = np.zeros((1,L))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                idx_data_in_bins[0,i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum\n",
    "                idx_data_in_bins[0,i] = 0   \n",
    "\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins[0,:] = idx_data_in_bins[0,:] / np.max(idx_data_in_bins[0,:])\n",
    "        all_data[idx,:] = idx_data_in_bins\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_label, index = df.index)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan_samples(spectrum,targets, c, cat):\n",
    "# if there are any NaN values, we should remove those samples\n",
    "    if (targets[cat].isnull().sum() > 0).all(): \n",
    "        merged = pd.concat([spectrum , targets],axis=1,copy=True)\n",
    "        clean = merged.dropna(subset=[cat])\n",
    "        Y = clean.iloc[:,-9+c].to_numpy().reshape(-1,)\n",
    "        X = clean.iloc[:,:-9]\n",
    "\n",
    "    else:\n",
    "        Y = targets.iloc[:,c].to_numpy().reshape(-1,)\n",
    "        X = spectrum.copy(deep=True)\n",
    "    return X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_in_bins_6(df, m, M, bin_size): # allows binsize < 1\n",
    "    \n",
    "    range_min = []; range_max = []; range_mean = []\n",
    "    for mz in np.arange(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_mean.append(np.mean([range_min[-1],range_max[-1]]))\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    for idx in range(N):\n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        interpolated_spectrum = np.interp(x=range_mean,xp=mzcoord,fp=intensity)\n",
    "        idx_data_in_bins = np.zeros((L,))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                # as we are interested in peak values, let's keep the maximum value in the interval\n",
    "                idx_data_in_bins[i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum we interpolate\n",
    "                idx_data_in_bins[i] = interpolated_spectrum[i]\n",
    "\n",
    "        # Remove baseline\n",
    "        idx_data_in_bins -= peakutils.baseline(idx_data_in_bins,deg=4)\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins = idx_data_in_bins / np.max(idx_data_in_bins)\n",
    "        # Store in matrix\n",
    "        all_data[idx,:] = idx_data_in_bins.reshape(1,-1)\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_mean, index = df.index)\n",
    "    print('DONE!')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data (spectra) and targets of the df_train set\n",
    "data = df_train.iloc[:,-2:]\n",
    "targets = df_train.iloc[:,1:-2] # so modify function to take targets.iloc[:,1:]\n",
    "IDs = df_train[['ID_sample']]\n",
    "\n",
    "limit = 100\n",
    "data_train = data.iloc[limit:,:]\n",
    "targets_train = targets.iloc[limit:,:]\n",
    "IDs_train = IDs.iloc[limit:,:]\n",
    "data_test_train = data.iloc[:limit,:]\n",
    "targets_test_train = targets.iloc[:limit,:]\n",
    "IDs_test_train = IDs.iloc[:limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_clf(clf, params, spectrum_train, targets_train, n_cv=5, njobs=5,\n",
    "            FEATURE_SELECTION=False, feature_vector_list=None):  \n",
    "    # new version --> Incorporates feature selection\n",
    "    t1 = time.time()\n",
    "\n",
    "    best_classifiers = []\n",
    "    grid_list = []\n",
    "    AUC_train = []; AUC_valid = []\n",
    "\n",
    "    categories = targets_train.columns[:]\n",
    "    for c, cat in enumerate(categories):\n",
    "\n",
    "        print([cat])  # indicate in which antibiotic we are\n",
    "\n",
    "        # Selection of train and test data (depending on whether there are NaN target values)\n",
    "        X_train, Y_train = clean_nan_samples(spectrum_train, targets_train, c, cat)\n",
    "\n",
    "        if FEATURE_SELECTION:  # a boolean that decides whether to apply feature selection\n",
    "            # (feature list has to be already defined, and input to the function)\n",
    "            X_train = apply_feature_selection(X_train, feature_vector_list[c])\n",
    "\n",
    "        # perform a GridSearchCV in order to train a classifier for this antibiotic\n",
    "        grid = GridSearchCV(clf, param_grid=params, scoring='roc_auc', n_jobs=njobs, \n",
    "                            pre_dispatch='2*n_jobs', cv=n_cv, return_train_score=True)\n",
    "        grid.fit(X_train, Y_train)\n",
    "\n",
    "        # print the best parameters (to detect edge values), and save that classifier\n",
    "        print('The best parameters are: ', grid.best_params_)\n",
    "        best_clf = grid.best_estimator_\n",
    "        best_classifiers.append(best_clf)\n",
    "        grid_list.append(grid)\n",
    "\n",
    "        best_clf = np.where(grid.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "        AUC_train.append(grid.cv_results_['mean_train_score'][best_clf])\n",
    "        AUC_valid.append(grid.cv_results_['mean_test_score'][best_clf])\n",
    "\n",
    "        print('Train AUC: ', np.round(AUC_train[-1], 4), ' and validation AUC: ', np.round(AUC_valid[-1], 4))\n",
    "\n",
    "    avg_AUC_train = np.mean(AUC_train)\n",
    "    avg_AUC_valid = np.mean(AUC_valid)\n",
    "    print('\\n\\nThe average train AUC is', np.round(avg_AUC_train, 4), 'and the avg validation AUC is',\n",
    "          np.round(avg_AUC_valid, 4))\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('\\nFull execution took ', np.round(t2 - t1, 1), 'seconds')\n",
    "    print('\\nDONE!')\n",
    "    return best_classifiers, grid_list, AUC_train, AUC_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_in_bins_5(df, m, M, bin_size): # allows binsize < 1\n",
    "    \n",
    "    range_min = []; range_max = []; range_mean = []\n",
    "    for mz in np.arange(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_mean.append(np.mean([range_min[-1],range_max[-1]]))\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    for idx in range(N):\n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        idx_data_in_bins = np.zeros((1,L))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                # as we are interested in peak values, let's keep the maximum value in the interval\n",
    "                idx_data_in_bins[0,i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum we interpolate\n",
    "                idx_data_in_bins[0,i] = np.interp(x=range_mean[i],xp=mzcoord,fp=intensity)\n",
    "\n",
    "        # Remove baseline\n",
    "        idx_data_in_bins[0,:] -= peakutils.baseline(idx_data_in_bins[0,:],deg=4)\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins[0,:] = idx_data_in_bins[0,:] / np.max(idx_data_in_bins[0,:])\n",
    "        # Store in matrix\n",
    "        all_data[idx,:] = idx_data_in_bins\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_mean, index = df.index)\n",
    "    print('DONE!')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "bin_size = 5; m = 2000; M = 12500;\n",
    "spectrum_train_normal5 = spectrum_in_bins_5(data_train,m,M,bin_size)\n",
    "spectrum_test_train_normal5 = spectrum_in_bins_5(data_test_train,m,M,bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 1, 'gamma': 0.5}\n",
      "Train AUC:  0.9026  and validation AUC:  0.7325\n",
      "['AMIKACINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 10, 'gamma': 0.1}\n",
      "Train AUC:  0.93  and validation AUC:  0.6612\n",
      "['AMOXI/CLAV']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 1, 'gamma': 0.5}\n",
      "Train AUC:  0.9024  and validation AUC:  0.7246\n",
      "['CIPROFLOXACINO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 10, 'gamma': 0.1}\n",
      "Train AUC:  0.9285  and validation AUC:  0.7587\n",
      "['CLINDAMICINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 0.5, 'gamma': 0.1}\n",
      "Train AUC:  0.7494  and validation AUC:  0.6466\n",
      "['ERITROMICINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 10, 'gamma': 1}\n",
      "Train AUC:  0.9953  and validation AUC:  0.662\n",
      "['LEVOFLOXACINO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 10, 'gamma': 0.1}\n",
      "Train AUC:  0.939  and validation AUC:  0.7745\n",
      "['PENICILINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 0.05, 'gamma': 5}\n",
      "Train AUC:  0.9988  and validation AUC:  0.6971\n",
      "['TOBRAMICINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are:  {'C': 5, 'gamma': 0.5}\n",
      "Train AUC:  0.9798  and validation AUC:  0.6666\n",
      "\n",
      "\n",
      "The average train AUC is 0.9251 and the avg validation AUC is 0.7026\n",
      "\n",
      "Full execution took  1398.4 seconds\n",
      "\n",
      "DONE!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_test_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-ba4bec53d8be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf_list_normal5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC_train_normal5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC_valid_normal5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspectrum_train_normal5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mAUC_test_normal5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_list_normal5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspectrum_test_train_normal5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_test_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_test_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(class_weight='balanced', probability=True,kernel='rbf')\n",
    "params = {'C':[0.05,0.1,0.5,1,5,10],'gamma':[0.01,0.1,0.5,1,5]}\n",
    "clf_list_normal5, grid_list, AUC_train_normal5, AUC_valid_normal5 = try_clf(clf, params, spectrum_train_normal5, targets_train)\n",
    "AUC_test_normal5 = get_test_score(clf_list_normal5, spectrum_test_train_normal5, targets_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions(clf_list, spectrum_test, IDs_test):\n",
    "    C = len(clf_list)\n",
    "    all_predictions_test = np.zeros((spectrum_test.shape[0], C))\n",
    "    for c in range(C):\n",
    "        pred_test = clf_list[c].predict_proba(spectrum_test)[:,1]\n",
    "        all_predictions_test[:,c] = pred_test.reshape(-1,)\n",
    "    df_pred_test = pd.DataFrame(data=all_predictions_test, index = spectrum_test.index, columns = targets.columns)\n",
    "#     df_pred_test[['ID_sample']] = IDs_test[['ID_sample']]\n",
    "    return df_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = get_test_predictions(clf_list_normal5, spectrum_test_train_normal5, IDs_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([targets_test_train, pred_test, IDs_test_train],axis=1,copy=True)\n",
    "clean = merged.dropna(subset=targets_test_train.columns)\n",
    "targets_test_train = clean.iloc[:,:9]\n",
    "pred_test = clean.iloc[:,9:-1]\n",
    "IDs_test_train = clean[['ID_sample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT WORKS!!\n",
    "Now get a better classifier :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# when I have all_predictions_test\n",
    "N = pred_test.shape[0]\n",
    "C = pred_test.shape[1]\n",
    "\n",
    "# get unique ID samples\n",
    "ID_samples = IDs_test_train.drop_duplicates(subset='ID_sample')\n",
    "ID_samples = ID_samples[['ID_sample']].to_numpy().astype(int).reshape(-1,)\n",
    "\n",
    "# create empty matrix for new predictions\n",
    "new_predictions = np.zeros((len(ID_samples),pred_test.shape[1]))\n",
    "\n",
    "# for each ID sample, compare both predictions and take the better one\n",
    "for counter, id in enumerate(ID_samples):\n",
    "#     print(id)\n",
    "    predictions = pred_test.loc[IDs_test_train['ID_sample'].to_numpy().astype(int)==id]\n",
    "#     print(predictions)\n",
    "    L = len(predictions)\n",
    "    if L > 1: # more than one spectrum for that sample\n",
    "        decisivity_index = np.zeros((L,)) # decisivity index ~= Gini = sum( (1-value)*value) \n",
    "        # --> low for close to 1 or 0, high for close to 0.5\n",
    "        for l in range(L):\n",
    "            di = 0\n",
    "            for c in range(C): # sum the decisivity index for all categories\n",
    "                val = predictions.iloc[l,c]\n",
    "                di += (1-val)*val\n",
    "            decisivity_index[l] = di\n",
    "        idx = np.argsort(decisivity_index)[0]\n",
    "        new_predictions[counter,:] = predictions.iloc[idx,:]\n",
    "\n",
    "    elif L==1: # just one prediction for that ID\n",
    "        new_predictions[counter,:] = predictions \n",
    "    else:\n",
    "        print('Weird, no sample for ID %d. Bug in code.' %id)\n",
    "        \n",
    "# save those results in a df with ID sample as ID\n",
    "predictions_more_expressive = pd.DataFrame(data = new_predictions, index = ID_samples, columns = targets.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OXACILINA</th>\n",
       "      <th>AMIKACINA</th>\n",
       "      <th>AMOXI/CLAV</th>\n",
       "      <th>CIPROFLOXACINO</th>\n",
       "      <th>CLINDAMICINA</th>\n",
       "      <th>ERITROMICINA</th>\n",
       "      <th>LEVOFLOXACINO</th>\n",
       "      <th>PENICILINA</th>\n",
       "      <th>TOBRAMICINA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    OXACILINA  AMIKACINA  AMOXI/CLAV  CIPROFLOXACINO  CLINDAMICINA  \\\n",
       "ID                                                                   \n",
       "24          0        0.0           0               0             0   \n",
       "28          1        1.0           1               1             0   \n",
       "30          0        0.0           0               1             0   \n",
       "34          0        0.0           0               0             0   \n",
       "52          0        0.0           0               0             0   \n",
       "\n",
       "    ERITROMICINA  LEVOFLOXACINO  PENICILINA  TOBRAMICINA  \n",
       "ID                                                        \n",
       "24             0            0.0           1          0.0  \n",
       "28             1            1.0           1          1.0  \n",
       "30             1            1.0           1          0.0  \n",
       "34             0            0.0           1          0.0  \n",
       "52             0            0.0           1          0.0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_withID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-6363d5f47cdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtargets_withID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets_withID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ID_sample'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtargets_withID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets_withID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ID_sample'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscore_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_withID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_more_expressive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'New score:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    353\u001b[0m     return _average_binary_score(\n\u001b[0;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[1;32m--> 119\u001b[1;33m                                  sample_weight=score_weight)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# Average the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    324\u001b[0m                              \"is not defined in that case.\")\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# get scores with targets_test\n",
    "targets_withID = targets_test_train.copy(deep=True)\n",
    "targets_withID[['ID_sample']] = IDs_test_train\n",
    "targets_withID = targets_withID.drop_duplicates(subset='ID_sample')\n",
    "targets_withID = targets_withID.drop(columns='ID_sample')\n",
    "score_new = roc_auc_score(targets_withID.to_numpy(), predictions_more_expressive)\n",
    "print('New score:',np.round(score_new,3))\n",
    "\n",
    "# get scores just making drop_unique\n",
    "pred_test_withID = pred_test.copy(deep=True)\n",
    "pred_test_withID[['ID_sample']] = IDs_test_train\n",
    "pred_test_withID = pred_test_withID.drop_duplicates(subset='ID_sample')\n",
    "pred_test_withID = pred_test_withID.drop(columns='ID_sample')\n",
    "score_old = roc_auc_score(targets_withID.to_numpy(), pred_test_withID)\n",
    "print('Old score:',np.round(score_old,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
