{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that we have several (two) spectra per sample. Then, instead of averaging them or discarding one of them randomly, let's select those results which are closer to zero or one (with some sort of Gini index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import _pickle\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2000; M = 12000; \n",
    "bin_size = 1;\n",
    "\n",
    "path = \"C:/Users/Javi/Documents/GitHub/Machine-Learning/Kaggle/\"\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TrainData.zip', 'r')\n",
    "df_train = _pickle.loads(zf.open('TrainData.pkl').read())\n",
    "zf.close()\n",
    "\n",
    "zf = zipfile.ZipFile(path+'zipped_TestDataUnlabeled.zip', 'r')\n",
    "df_test = _pickle.loads(zf.open('TestDataUnlabeled.pkl').read())\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_in_bins(df,m,M,bin_size):\n",
    "    # Now, let's define the mz ranges, and the label associated to each of them (the mean of the limiting values of each bin)\n",
    "    range_min = []; range_max = []; range_label = [];\n",
    "    for mz in range(m,M,bin_size):\n",
    "        range_min.append(mz)\n",
    "        range_max.append(mz+bin_size)\n",
    "        range_label.append(np.mean([range_min[-1],range_max[-1]]).astype(int))\n",
    "    N = len(df)  # number of samples\n",
    "    L = len(range_min)  # length of new spectrum (number of bins)\n",
    "    all_data = np.zeros((N,L))\n",
    "    for idx in range(N): \n",
    "        intensity = df[['intensity']].iloc[idx].values[0]\n",
    "        mzcoord   = df[['coord_mz']].iloc[idx].values[0]\n",
    "        idx_data_in_bins = np.zeros((1,L))\n",
    "        for i,mz in enumerate(range_min):\n",
    "            intensity_range = intensity[(mzcoord > mz) & (mzcoord < (mz+bin_size))]\n",
    "            if len(intensity_range) > 0 :\n",
    "                idx_data_in_bins[0,i] = np.max(intensity_range)\n",
    "            else: # if those mz coordinates are not in that spectrum\n",
    "                idx_data_in_bins[0,i] = 0   \n",
    "\n",
    "        # Normalize the amplitude of the spectrum\n",
    "        idx_data_in_bins[0,:] = idx_data_in_bins[0,:] / np.max(idx_data_in_bins[0,:])\n",
    "        all_data[idx,:] = idx_data_in_bins\n",
    "    new_df = pd.DataFrame(data=all_data, columns = range_label, index = df.index)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan_samples(spectrum,targets, c, cat):\n",
    "# if there are any NaN values, we should remove those samples\n",
    "    if (targets[cat].isnull().sum() > 0).all(): \n",
    "        merged = pd.concat([spectrum , targets],axis=1,copy=True)\n",
    "        clean = merged.dropna(subset=[cat])\n",
    "        Y = clean.iloc[:,-9+c].to_numpy().reshape(-1,)\n",
    "        X = clean.iloc[:,:-9]\n",
    "\n",
    "    else:\n",
    "        Y = targets.iloc[:,c].to_numpy().reshape(-1,)\n",
    "        X = spectrum.copy(deep=True)\n",
    "    return X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrum regularized!\n"
     ]
    }
   ],
   "source": [
    "# Extract data (spectra) and targets of the df_train set\n",
    "data = df_train.iloc[:,-2:]\n",
    "targets = df_train.iloc[:,1:-2] # so modify function to take targets.iloc[:,1:]\n",
    "IDs = df_train[['ID_sample']]\n",
    "\n",
    "limit = 350\n",
    "data_train = data.iloc[:limit,:]\n",
    "targets_train = targets.iloc[:limit,:]\n",
    "IDs_train = IDs.iloc[:limit,:]\n",
    "data_test_train = data.iloc[limit:,:]\n",
    "targets_test_train = targets.iloc[limit:,:]\n",
    "IDs_test_train = IDs.iloc[limit:,:]\n",
    "\n",
    "spectrum_train = spectrum_in_bins(data_train,m,M,bin_size)\n",
    "spectrum_test_train = spectrum_in_bins(data_test_train,m,M,bin_size)\n",
    "print('Spectrum regularized!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_sample</th>\n",
       "      <th>OXACILINA</th>\n",
       "      <th>AMIKACINA</th>\n",
       "      <th>AMOXI/CLAV</th>\n",
       "      <th>CIPROFLOXACINO</th>\n",
       "      <th>CLINDAMICINA</th>\n",
       "      <th>ERITROMICINA</th>\n",
       "      <th>LEVOFLOXACINO</th>\n",
       "      <th>PENICILINA</th>\n",
       "      <th>TOBRAMICINA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1811</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1811</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_sample  OXACILINA  AMIKACINA  AMOXI/CLAV  CIPROFLOXACINO  CLINDAMICINA  \\\n",
       "ID                                                                              \n",
       "350      1776          1        0.0           1               0             1   \n",
       "351      1788          1        1.0           1               1             0   \n",
       "352      1788          1        1.0           1               1             0   \n",
       "353      1811          1        1.0           1               1             1   \n",
       "354      1811          1        1.0           1               1             1   \n",
       "\n",
       "     ERITROMICINA  LEVOFLOXACINO  PENICILINA  TOBRAMICINA  \n",
       "ID                                                         \n",
       "350             1            0.0           1          0.0  \n",
       "351             0            1.0           1          1.0  \n",
       "352             0            1.0           1          1.0  \n",
       "353             1            1.0           1          1.0  \n",
       "354             1            1.0           1          1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_clf(clf,params,n_cv=5): # also output prediction for test set\n",
    "    t1 = time.time()\n",
    "    \n",
    "    best_classifiers = [];\n",
    "    accuracies_train = []; accuracies_test_train = [];\n",
    "    AUC_train = []; AUC_test_train = [];\n",
    "    \n",
    "    categories = targets_train.columns[:]    \n",
    "    for c,cat in enumerate(categories):\n",
    "\n",
    "        print([cat]) # indicate in which antibiotic we are\n",
    "        \n",
    "        # Selection of train and test data (depending on whether there are NaN target values)\n",
    "        X_train, Y_train = clean_nan_samples(spectrum_train,targets_train, c, cat)\n",
    "        X_test_train, Y_test_train = clean_nan_samples(spectrum_test_train,targets_test_train, c, cat)\n",
    "            \n",
    "        # perform a GridSearchCV in order to train a classifier for this antibiotic\n",
    "        grid = GridSearchCV(clf,param_grid=params, cv=n_cv, iid=False, scoring='roc_auc')\n",
    "        grid.fit(X_train, Y_train)\n",
    "\n",
    "        # print the best parameters (to detect edge values), and save that classifier\n",
    "        print('The best parameters are: ',grid.best_params_)\n",
    "        best_clf = grid.best_estimator_\n",
    "        best_classifiers.append(best_clf)\n",
    "\n",
    "\n",
    "        # compute the AUC of the classifier\n",
    "        if callable(getattr(best_clf,\"predict_proba\",None)):\n",
    "            pred_train = best_clf.predict_proba(X_train)[:,-1] # only take last column, the prob of Y = +1\n",
    "            pred_test = best_clf.predict_proba(X_test_train)[:,-1]\n",
    "        else:\n",
    "            print('Using decision_function instead of predict_proba')\n",
    "            pred_train = best_clf.decision_function(X_train)\n",
    "            pred_test = best_clf.decision_function(X_test_train)            \n",
    "        auc_score_train = roc_auc_score(Y_train, pred_train)\n",
    "        auc_score_test = roc_auc_score(Y_test_train, pred_test)\n",
    "        print('Train AUC: ',np.round(auc_score_train,4),' and test_train AUC: ',np.round(auc_score_test,4))\n",
    "        AUC_train.append(auc_score_train)\n",
    "        AUC_test_train.append(auc_score_test)\n",
    "        \n",
    "    avg_AUC_train = np.mean(AUC_train)\n",
    "    avg_AUC_test_train = np.mean(AUC_test_train)\n",
    "    print('\\n\\nThe average train AUC is',np.round(avg_AUC_train,4),'and the avg test_train AUC is',np.round(avg_AUC_test_train,4))\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print('\\nFull execution took ',np.round(t2-t1,1),'seconds')\n",
    "    print('\\nDONE!')\n",
    "    return best_classifiers, AUC_train, AUC_test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OXACILINA']\n",
      "The best parameters are:  {'C': 0.5}\n",
      "Train AUC:  0.9118  and test_train AUC:  0.7135\n",
      "['AMIKACINA']\n",
      "The best parameters are:  {'C': 1}\n",
      "Train AUC:  0.9382  and test_train AUC:  0.646\n",
      "['AMOXI/CLAV']\n",
      "The best parameters are:  {'C': 1}\n",
      "Train AUC:  0.9267  and test_train AUC:  0.6764\n",
      "['CIPROFLOXACINO']\n",
      "The best parameters are:  {'C': 1}\n",
      "Train AUC:  0.934  and test_train AUC:  0.7628\n",
      "['CLINDAMICINA']\n",
      "The best parameters are:  {'C': 0.1}\n",
      "Train AUC:  0.7508  and test_train AUC:  0.523\n",
      "['ERITROMICINA']\n",
      "The best parameters are:  {'C': 1}\n",
      "Train AUC:  0.8893  and test_train AUC:  0.6038\n",
      "['LEVOFLOXACINO']\n",
      "The best parameters are:  {'C': 1}\n",
      "Train AUC:  0.9478  and test_train AUC:  0.8245\n",
      "['PENICILINA']\n",
      "The best parameters are:  {'C': 0.1}\n",
      "Train AUC:  0.8449  and test_train AUC:  0.8071\n",
      "['TOBRAMICINA']\n",
      "The best parameters are:  {'C': 1}\n",
      "Train AUC:  0.942  and test_train AUC:  0.6389\n",
      "\n",
      "\n",
      "The average train AUC is 0.8984 and the avg test_train AUC is 0.6884\n",
      "\n",
      "Full execution took  282.7 seconds\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(class_weight='balanced', probability=True,kernel='linear')\n",
    "params = {'C':[0.1,0.5,1]}\n",
    "best_classifiers, AUC_train, AUC_test_train = try_clf(clf,params,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions(clf_list, spectrum_test, IDs_test):\n",
    "    C = len(clf_list)\n",
    "    all_predictions_test = np.zeros((spectrum_test.shape[0], C))\n",
    "    for c in range(C):\n",
    "        pred_test = clf_list[c].predict_proba(spectrum_test)[:,1]\n",
    "        all_predictions_test[:,c] = pred_test.reshape(-1,)\n",
    "    df_pred_test = pd.DataFrame(data=all_predictions_test, index = spectrum_test.index, columns = targets.columns)\n",
    "#     df_pred_test[['ID_sample']] = IDs_test[['ID_sample']]\n",
    "    return df_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = get_test_predictions(best_classifiers, spectrum_test_train, IDs_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "# when I have all_predictions_test\n",
    "N = pred_test.shape[0]\n",
    "C = pred_test.shape[1]\n",
    "\n",
    "# get unique ID samples\n",
    "ID_samples = IDs_test_train.drop_duplicates(subset='ID_sample')\n",
    "ID_samples = ID_samples[['ID_sample']].to_numpy().astype(int).reshape(-1,)\n",
    "\n",
    "# create empty matrix for new predictions\n",
    "new_predictions = np.zeros((len(ID_samples),pred_test.shape[1]))\n",
    "\n",
    "# for each ID sample, compare both predictions and take the better one\n",
    "for counter, id in enumerate(ID_samples):\n",
    "#     print(id)\n",
    "    predictions = pred_test.loc[IDs_test_train['ID_sample'].to_numpy().astype(int)==id]\n",
    "#     print(predictions)\n",
    "    L = len(predictions)\n",
    "    if L > 1: # more than one spectrum for that sample\n",
    "        decisivity_index = np.zeros((L,))\n",
    "        for l in range(L):\n",
    "            \n",
    "            \n",
    "            # compute \"decisivity_index\"\n",
    "            print('a')\n",
    "            \n",
    "    elif L==1: # just one prediction for that ID\n",
    "        new_predictions[counter,:] = predictions \n",
    "    else:\n",
    "        print('Weird, no sample for that ID. Bug in code.')\n",
    "        \n",
    "# save those results in a df with ID sample as ID\n",
    "predictions_more_expressive = pd.DataFrame(data = new_predictions, index = ID_samples, columns = targets.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-c60bcaf44555>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtargets_withID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ID_sample'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtargets_withID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ID_sample'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscore_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_test_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpartial_auc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_area\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_area\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'f'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# get scores with targets_test\n",
    "targets_withID = targets_test_train.copy(deep=True)\n",
    "targets_withID[['ID_sample']] = IDs_test_train\n",
    "targets_withID.drop_duplicates(subset='ID_sample')\n",
    "targets_withID.drop(columns='ID_sample')\n",
    "score_new = roc_auc_score(targets_test_train.to_numpy(), new_predictions)\n",
    "\n",
    "\n",
    "# get scores just making drop_unique\n",
    "pred_test_withID = pred_test.copy(deep=True)\n",
    "pred_test_withID[['ID_sample']] = IDs_test_train\n",
    "pred_test_withID.drop_duplicates(subset='ID_sample')\n",
    "pred_test_withID.drop(columns='ID_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OXACILINA         0\n",
       "AMIKACINA         0\n",
       "AMOXI/CLAV        0\n",
       "CIPROFLOXACINO    0\n",
       "CLINDAMICINA      0\n",
       "ERITROMICINA      0\n",
       "LEVOFLOXACINO     2\n",
       "PENICILINA        0\n",
       "TOBRAMICINA       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(targets_test_train.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OXACILINA</th>\n",
       "      <th>AMIKACINA</th>\n",
       "      <th>AMOXI/CLAV</th>\n",
       "      <th>CIPROFLOXACINO</th>\n",
       "      <th>CLINDAMICINA</th>\n",
       "      <th>ERITROMICINA</th>\n",
       "      <th>LEVOFLOXACINO</th>\n",
       "      <th>PENICILINA</th>\n",
       "      <th>TOBRAMICINA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [OXACILINA, AMIKACINA, AMOXI/CLAV, CIPROFLOXACINO, CLINDAMICINA, ERITROMICINA, LEVOFLOXACINO, PENICILINA, TOBRAMICINA]\n",
       "Index: []"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
